
kafka.backoff.interval=2000
kafka.backoff.max_failure=3

kafka.backoff.retry.topic=producer_json_retry
kafka.backoff.DLT=producer_json_DLT

spring.kafka.consumer.bootstrap-servers: localhost:9092
spring.kafka.consumer.group-id: group-id
spring.kafka.consumer.auto-offset-reset: earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.properties.isolation.level=read_committed
spring.kafka.consumer.key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*

spring.kafka.producer.bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
spring.kafka.producer.key-serializer: org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

spring.kafka.bootstrap-servers=localhost:9092,localhost:9093,localhost:9094
spring.kafka.producer.retries=3






acks stratgy    
    acks=0
    acks=1
    acks=all
    
 



--consumer

    topic
    partition
    replication
    partition leader- in-sync replication
    offset topic
    consumer offset topic
    consumer groups

    what is the setting consuption modes ?
        atleastOnce
        atMostOnce
        exactlyOnce


is zookeper mandate?


ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1


replicationFactor
partitions


segments and Index


























